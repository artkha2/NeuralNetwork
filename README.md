# NeuralNetwork

The project is built with the help of this tutorial: https://www.youtube.com/watch?v=w8yWXqWQYmU


## If you tried to implement a solution using “brute force”, would it work effectively? Why or why not?
In the case of a neural network, the brute force solution would be to manually set every parameter. Guessing every weight and bias combination is impossible. In the case of the MNIST dataset, there are 2 layers, each with 10 nodes (one for each possible digit). Since each image is 28x28 pixels, the first layer has 784*10 = 7,840 weights in its matrix, and the second layer has 10*10 = 100. This would mean manually guessing and checking thousands of weights and biases, which means either I would have to spend countless hours fine-tuning the weights, or the neural network would be extremely inaccurate. In contrast, using backpropagation with 500 iterations resulted in a pretty high accuracy model within a minute.

## Did your solution work effectively to solve your problem? Why or why not?
The model taken from the tutorial, after minor bug fixes in the softmax function, achieved 85% accuracy for the MNIST dataset. Given the model was very simple, quick, and used only 2 layers, that accuracy can be considered relatively high. When I implemented the model myself and adapted it to the Iris dataset, it achieved an accuracy of 90-97%, and during some runs, accurately classified 100% of the flowers in the test dataset. Therefore, the solution did work effectively to solve my problem.

## What are some of the issues with your solution?
The original solution from the tutorial had multiple bugs. For example, during backpropagation, the bias differences were incorrectly computed. Due to the wrong dimensions being used, the db was a scalar number rather than a vector as intended. The same issue happened with the softmax function. However, because of how large the MNIST dataset is and the number of features it has, the model still performed well, achieving a high accuracy. When I re-implemented the model with the Iris dataset, which only has 150 points in the sample and only 4 features, these issues ruined the whole model. When I updated the relevant functions to maintain the correct dimensions, the model behaved as expected. However, even with this corrected solution, some issues remain. I hardcoded the train-test splitting instead of using stratified sampling or k-fold validation, which means the accuracy can vary widely from run to run, especially for a small dataset. This also makes it hard to do any fine-tuning for the model, such as increasing the number of neurons or choosing a different hyperparameter alpha (training rate) and systematically comparing the accuracy. As such, the model can be potentially underfitting or overfitting the data. Finally, my model doesn’t provide any interpretability. We don’t know which features are the most important or how confident the mode is, which matters in real-world tasks. However, given that the neural network is very simple and built from scratch, addressing these issues would significantly increase the complexity of the project.

## What are some of the edge cases with your solution?
The train-test splitting relies on a random shuffle of the data. A potential edge case could be all examples of one class ending up in the test set due to a bad shuffle, in which case the model would be unable to classify them. This is especially likely in a small dataset. Also, I use min-max normalization for the input, so in the edge case where all features have the same value (zero variance), normalization could cause division by zero or NaNs. Similarly, if the data contains unexpected or corrupted inputs (e.g. NaNs, strings), the model will fail since I do not clean the data or do any preprocessing. Finally, the parameters are initialized randomly and the learning rate is picked arbitrarily, so it is possible - though unlikely - that the model will never converge. This can happen when, for example, the learning rate is too high or random initial weights land in dead ReLUs or near-zero gradients.

## How might you improve your idea in the future?
One obvious improvement would be to do proper robust model validation as described above. This would allow me to select the most optimal model architecture and hyperparameters. In addition, more layers could be added to increase accuracy, and the learning rate (alpha) can be changed to an adaptive optimizer rather than remaining constant throughout training. To prevent some of the edge cases described above, the initial weights can be initialized using Kaiming He initialization, which takes into account the nonlinearity of activation functions and can lead to better accuracy in fewer iterations. To avoid overfitting, I could implement early stopping or regularization. To make the model more efficient and faster, I could use mini-batch gradient descent. Finally, for overall scalability, reliability, and consistency, I could use a framework like TensorFlow or PyTorch instead of implementing everything from scratch.

